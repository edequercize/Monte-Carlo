{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example \n",
    "n = 2\n",
    "p = 2\n",
    "X = np.random.normal(0, 1, (n, p))\n",
    "y = np.random.normal(0, 1, n)\n",
    "X_transpose = X.T\n",
    "beta= [1,2]\n",
    "beta_init= [1,2]\n",
    "zeta_init = 6\n",
    "eta_init =1\n",
    "\n",
    "j=1\n",
    "eta = [1,2]\n",
    "sigma_sq=1\n",
    "num_iterations=1000\n",
    "nu=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import invgamma, multivariate_normal, t, gamma\n",
    "from numpy.linalg import cholesky\n",
    "\n",
    "\n",
    "np.random.seed(200)\n",
    "\n",
    "# Nombre d'observations\n",
    "nombre_observations = 50\n",
    "\n",
    "# Matrice de mod√®le simul√©e\n",
    "X = np.column_stack([np.ones(nombre_observations), np.random.normal(0, 1, nombre_observations),\n",
    "                     np.random.normal(5, 10, nombre_observations), np.random.normal(100, 10, nombre_observations)])\n",
    "\n",
    "# Vrais coefficients beta\n",
    "vrais_coefficients_beta = np.array([1000, 50, -50, 10])\n",
    "\n",
    "# Vraie valeur de phi\n",
    "vraie_phi = 10000\n",
    "matrice_identite = np.eye(nombre_observations)  # Matrice identit√© utilis√©e pour la matrice de covariance\n",
    "\n",
    "# Simuler la variable d√©pendante pour la r√©gression\n",
    "y = multivariate_normal.rvs(mean=np.dot(X, vrais_coefficients_beta),\n",
    "                            cov=vraie_phi * matrice_identite)\n",
    "\n",
    "# valeurs initiales\n",
    "n,p = X.shape\n",
    "\n",
    "beta_sampled = np.zeros(p)\n",
    "eta_sampled = np.zeros(p)\n",
    "zeta_sampled = 0\n",
    "sigma_sampled = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5740237589254495\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour calculer mu_j\n",
    "def compute_mu_j(beta, X, y, eta, sigma_sq, j):\n",
    "    eta_j=eta[j]\n",
    "    n = X.shape[0]\n",
    "    mu_j = np.sum(X[:, j] * (y - np.dot(X, beta) + X[:, j] * beta[j])) / (X[:, j].dot(X[:, j]) / eta_j + 1 / sigma_sq)\n",
    "    return mu_j\n",
    "\n",
    "print(compute_mu_j(beta, X, y, eta, sigma_sq, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4223769858205402\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour calculer sigma_j^2\n",
    "def compute_sigma_j_sq(X, eta, sigma_sq, j):\n",
    "    eta_j=eta[j]\n",
    "    sigma_j_sq = 1 / (X[:, j].dot(X[:, j]) / eta_j + 1 / sigma_sq)\n",
    "    return sigma_j_sq\n",
    "\n",
    "print(compute_sigma_j_sq(X, eta, sigma_sq, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Densit√© a posteriori conditionnelle de eta_t+1 : 3.2701949932084803e-10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def density_eta(eta_sampled, beta_t, sigma_sq, zeta_t, nu):\n",
    "    \"\"\"\n",
    "    Calcul de la densit√© a posteriori conditionnelle de eta_t+1.\n",
    "\n",
    "    Arguments :\n",
    "    eta_sampled : Valeurs √©chantillonn√©es de eta_t+1.\n",
    "    beta_t : Vecteur de coefficients beta_t.\n",
    "    sigma_sq : Variance sigma_t^2.\n",
    "    zeta_t : Valeur zeta_t.\n",
    "    nu : Param√®tre nu.\n",
    "\n",
    "    Returns :\n",
    "    posterior_density : Densit√© a posteriori conditionnelle de eta_t+1.\n",
    "    \"\"\"\n",
    "    p = len(eta_sampled)\n",
    "    posterior_density = 1\n",
    "\n",
    "    for j in range(p):\n",
    "        m_tj = zeta_t * beta_t[j]**2 / (2 * sigma_sq)\n",
    "        # Terme exponentiel\n",
    "        exp_term = np.exp(-m_tj * eta_sampled[j])\n",
    "        # Terme de normalisation\n",
    "        normalization_term = eta_sampled[j]**((1 - nu) / 2) * (1 + nu * eta_sampled[j])**(nu + 1)\n",
    "        # Mise √† jour de la densit√© a posteriori conditionnelle\n",
    "        posterior_density *= exp_term / normalization_term\n",
    "\n",
    "    return posterior_density\n",
    "\n",
    "# Exemple d'utilisation\n",
    "eta_sampled = np.array([1, 2, 3])  # Exemple de valeurs √©chantillonn√©es de eta_t+1\n",
    "beta_t = np.array([0.5, 0.8, 1.2])  # Exemple de coefficients beta_t\n",
    "sigma_sq = 0.5  # Exemple de variance sigma_t^2\n",
    "zeta_t = 1.5  # Exemple de valeur zeta_t\n",
    "nu = 2  # Exemple de param√®tre nu\n",
    "\n",
    "posterior_density = eta_t_plus_1(eta_sampled, beta_t, sigma_sq, zeta_t, nu)\n",
    "print(\"Densit√© a posteriori conditionnelle de eta_t+1 :\", posterior_density)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.780519320552555\n"
     ]
    }
   ],
   "source": [
    "u = np.random.uniform(0,4)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fonction pour √©valuer la fonction de densit√© de la distribution conditionnelle de chaque composante de ùúº_t\n",
    "def cond_density_eta(eta_j, beta, sigma2, mu, X, y):\n",
    "    # Calculer la matrice de covariance Sigma\n",
    "    Sigma = np.linalg.inv(np.dot(X.T, X) + mu * np.eye(X.shape[1]))\n",
    "    # Calculer le vecteur de moyenne m\n",
    "    m = np.dot(Sigma, np.dot(X.T, y))\n",
    "    # Calculer la valeur de la fonction de densit√© de la distribution conditionnelle de eta_j\n",
    "    density = np.exp(-mu * eta_j**2 / (2 * sigma2)) * np.exp(-np.dot(beta - m, np.dot(Sigma, beta - m)) / (2 * sigma2))\n",
    "    return density\n",
    "\n",
    "# Fonction pour impl√©menter le slice sampling pour chaque composante de ùúº_t\n",
    "def slice_sampling_eta(beta, sigma2, mu, X, y, n_samples):\n",
    "    # Initialiser la matrice des √©chantillons de ùúº_t\n",
    "    eta_samples = np.zeros((n_samples, X.shape[1]))\n",
    "    # Initialiser la valeur initiale de ùúº_t\n",
    "    eta = np.random.normal(0, 1, X.shape[1])\n",
    "    # It√©ration du slice sampling pour chaque composante de ùúº_t\n",
    "    for j in range(X.shape[1]):\n",
    "        # It√©ration du slice sampling pour chaque √©chantillon de ùúº_t,j\n",
    "        for i in range(n_samples):\n",
    "            # √âvaluer la fonction de densit√© de la distribution conditionnelle de eta_j √† la valeur actuelle de eta_j\n",
    "            density = cond_density_eta(eta[j], beta, sigma2, mu, X, y)\n",
    "            # G√©n√©rer une valeur al√©atoire uniforme entre 0 et la valeur de la fonction de densit√©\n",
    "            u = np.random.uniform(0, density)\n",
    "            # Trouver l'intervalle horizontal qui contient u dans le graphique de la fonction de densit√©\n",
    "            # Utiliser la recherche par dichotomie pour trouver l'intervalle\n",
    "            lower_bound = eta[j] - 1\n",
    "            upper_bound = eta[j] + 1\n",
    "            while True:\n",
    "                if cond_density_eta(lower_bound, beta, sigma2, mu, X, y) < u:\n",
    "                    lower_bound = (lower_bound + eta[j]) / 2\n",
    "                elif cond_density_eta(upper_bound, beta, sigma2, mu, X, y) < u:\n",
    "                    upper_bound = (upper_bound + eta[j]) / 2\n",
    "                else:\n",
    "                    break\n",
    "            # G√©n√©rer une valeur al√©atoire uniforme dans l'intervalle horizontal\n",
    "            eta_new = np.random.uniform(lower_bound, upper_bound)\n",
    "            # Accepter la nouvelle valeur avec probabilit√© 1\n",
    "            eta[j] = eta_new\n",
    "            # Enregistrer la valeur actuelle de eta_j dans la matrice des √©chantillons\n",
    "            eta_samples[i, j] = eta[j]\n",
    "    return eta_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√©ta_sampled [array([-0.51751846,  0.02954253, -0.17998958, -0.70085128])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def slice_sampling_eta(beta, sigma_sq, zeta, nu, initial_value_eta, num_samples, step_size=1.0):\n",
    "    samples_eta = [initial_value_eta]\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        current_value_eta = samples_eta[-1]\n",
    "        # √âtape de \"slice\"\n",
    "        height_eta = np.random.uniform(0, target_density_eta(current_value_eta, beta, sigma_sq, zeta, nu))\n",
    "        # √âtape de r√©duction de la tranche\n",
    "        left_eta = current_value_eta - np.random.exponential(scale=step_size)\n",
    "        right_eta = left_eta + step_size\n",
    "        while target_density_eta(left_eta, beta, sigma_sq, zeta, nu) < height_eta:\n",
    "            left_eta -= step_size\n",
    "        while target_density_eta(right_eta, beta, sigma_sq, zeta, nu) < height_eta:\n",
    "            right_eta += step_size\n",
    "        # √âtape d'√©chantillonnage\n",
    "        new_value_eta = np.random.uniform(left_eta, right_eta)\n",
    "        samples_eta.append(new_value_eta)\n",
    "        \n",
    "    return samples_eta[1:]  # On retire la valeur initiale\n",
    "\n",
    "\n",
    "def target_density_eta(eta, beta, sigma_sq, zeta, nu):\n",
    "    p = len(beta)\n",
    "    density = 1.0\n",
    "    for j in range(p):\n",
    "        m_tj = zeta * beta[j]**2 / (2 * sigma_sq)\n",
    "        term1 = np.exp(-m_tj * eta[j])\n",
    "        term2 = eta[j]**((1 - nu) / 2) * (1 + nu * eta[j])**(nu + 1)\n",
    "        density *= term1 / term2\n",
    "    return density\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # Ex√©cution de l'algorithme de slice sampling pour √©chantillonner eta\n",
    "    samples_eta = slice_sampling_eta(beta_sampled, 1, zeta_sampled, 1, eta_sampled, 1, 1)\n",
    "    \n",
    "    # Affichage des r√©sultats\n",
    "    print(\"√©ta_sampled\", samples_eta)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# il faut faire une fonction calculate_likelihood ici \n",
    "\n",
    "def calculate_likelihood(X, y, beta_t, zeta_t_plus_1, eta_t_plus_1):    # il faut que les b√©ta_sampled et les sigma_sq_sampled existe pour le faire.\n",
    "    \"\"\"\n",
    "    Calcule la vraisemblance de y sachant zeta_t+1 et eta_t+1.\n",
    "\n",
    "    Arguments :\n",
    "    y : Vecteur des observations.\n",
    "    X : Matrice des pr√©dicteurs.\n",
    "    beta_t : √âchantillons de beta √† t.\n",
    "    sigma_sq_samples : √âchantillons de sigma_sq.\n",
    "    zeta : Valeur de zeta_t+1.\n",
    "    eta : Vecteur des valeurs eta_t+1.\n",
    "\n",
    "    Returns :\n",
    "    likelihood : La vraisemblance de y sachant zeta_t+1 et eta_t+1.\n",
    "    \"\"\"\n",
    "    n_samples = len(beta_t)\n",
    "    likelihood = 0\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        beta = beta_t[i]\n",
    "        sigma_sq = sigma_sq_samples[i]\n",
    "        \n",
    "        # Calcul de la densit√© conditionnelle de y sachant beta et sigma_sq\n",
    "        data_density = np.exp(-0.5 * n * np.log(2 * np.pi * sigma_sq) - 0.5 * np.linalg.slogdet(Sigma)[1] \\\n",
    "                     - 0.5 * np.dot(np.dot((y - np.dot(X.T, beta)).T, np.linalg.inv(Sigma)), (y - np.dot(X.T, beta))))\n",
    "        \n",
    "        # Calcul de la densit√© jointe de beta et sigma_sq sachant zeta_t+1 et eta_t+1\n",
    "        joint_prior = np.exp(-0.5 * np.sum(beta**2) / (zeta_t_plus_1 * eta_t_plus_1) - 0.5 * np.log(sigma_sq))\n",
    "        \n",
    "        # Ajout de la contribution de cet √©chantillon √† la vraisemblance\n",
    "        likelihood += data_density * joint_prior\n",
    "    \n",
    "    # Moyenne des contributions de tous les √©chantillons\n",
    "    likelihood /= n_samples\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "\n",
    "\n",
    "def sample_zeta_t_plus_1(zeta_t, eta_t_plus_1, sigma_sq, sigma_mrth=0.8): \n",
    "# y, X, beta, sigma_sq ???\n",
    "    \n",
    "    \"\"\"\n",
    "    √âchantillonne la valeur de zeta_t+1 conditionnellement √† zeta_t et eta_t+1.\n",
    "\n",
    "    Arguments :\n",
    "    zeta_t : Valeur zeta_t.\n",
    "    eta_t_plus_1 : Valeur √©chantillonn√©e de eta_t+1.\n",
    "    y : Vecteur de donn√©es.\n",
    "    X : Matrice de design.\n",
    "    beta : Vecteur de coefficients beta_t.\n",
    "    sigma_sq : Variance sigma_t^2.\n",
    "    sigma_mrth : √âcart-type de la proposition normale = 0.8 selon l'article.\n",
    "\n",
    "    Returns :\n",
    "    zeta_sampled : Valeur √©chantillonn√©e de zeta_t+1.\n",
    "    \"\"\"\n",
    "    zeta_proposed = zeta_t\n",
    "    # Calcul de la matrice Sigma\n",
    "    Sigma = np.dot(X, X.T) + zeta_proposed * np.diag(eta_t_plus_1)\n",
    "\n",
    "    # Proposition d'un nouvel √©chantillon de log(zeta_t+1)\n",
    "    log_zeta_proposed = np.random.normal(np.log(zeta_t), sigma_mrth)\n",
    "\n",
    "    # Calcul des termes de probabilit√© a priori\n",
    "    prior_current = -0.5 * zeta_t ** 2\n",
    "    prior_proposed = -0.5 * np.exp(2 * log_zeta_proposed)\n",
    "\n",
    "    # On calcule la vraisemblance conditionnelle des donn√©es\n",
    "    log_likelihood = np.log(calculate_likelihood(X, y, beta_t, zeta_proposed, eta_t_plus_1)) # cf fonction calculate_likelihood au dessus\n",
    "    \n",
    "    # Log-probabilit√© du log-posterior pour les valeurs actuelles et propos√©es\n",
    "    log_posterior_current = log_likelihood + prior_current\n",
    "    log_posterior_proposed = log_likelihood + prior_proposed\n",
    "\n",
    "    # Calcul du ratio de probabilit√©\n",
    "    acceptance_ratio = np.exp(log_posterior_proposed - log_posterior_current)\n",
    "\n",
    "    # Acceptation ou rejet de la proposition\n",
    "    if np.random.uniform(0, 1) < acceptance_ratio:\n",
    "        zeta_sampled = np.exp(log_zeta_proposed)\n",
    "    else:\n",
    "        zeta_sampled = zeta_t\n",
    "\n",
    "    return zeta_sampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/onyxia/work/Monte-Carlo-1/standard gibbs.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://user-garancelat-703356-0.user.lab.sspcloud.fr/home/onyxia/work/Monte-Carlo-1/standard%20gibbs.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m         beta_current \u001b[39m=\u001b[39m beta_new\n\u001b[1;32m     <a href='vscode-notebook-cell://user-garancelat-703356-0.user.lab.sspcloud.fr/home/onyxia/work/Monte-Carlo-1/standard%20gibbs.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m beta_current\n\u001b[0;32m---> <a href='vscode-notebook-cell://user-garancelat-703356-0.user.lab.sspcloud.fr/home/onyxia/work/Monte-Carlo-1/standard%20gibbs.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(gibbs_sampling(X, y, beta_init, eta, sigma_sq, num_iterations))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Fonction pour l'√©chantillonnage de Gibbs\n",
    "def gibbs_sampling(X, y, beta_init, eta_init, zeta_init, sigma_sq, num_iterations, nu):\n",
    "    num_features = X.shape[1]\n",
    "    zeta = zeta_init\n",
    "    eta = eta_init\n",
    "    # Boucle sur le nombre d'it√©rations\n",
    "    for t in range(num_iterations):\n",
    "        beta_new = beta_init\n",
    "        eta = sample_eta_t_plus_1(beta_new, sigma_sq, zeta, nu)\n",
    "        zeta = sample_zeta(zeta, eta, sigma_sq, sigma_mrth=0.8)\n",
    "        \n",
    "        # Boucle sur chaque coordonn√©e beta_j\n",
    "        for j in range(num_features):\n",
    "            mu_j = compute_mu_j(beta_new, X, y, eta, sigma_sq, j)\n",
    "            sigma_j_sq = compute_sigma_j_sq(X, eta, sigma_sq, j)\n",
    "            beta_new[j] = np.random.normal(mu_j, np.sqrt(sigma_j_sq))\n",
    "        \n",
    "        # Mettre √† jour les coordonn√©es beta pour l'it√©ration suivante\n",
    "        beta_current = beta_new\n",
    "    \n",
    "    return beta_current\n",
    "\n",
    "print(gibbs_sampling(X, y, beta_init, eta, sigma_sq, num_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
